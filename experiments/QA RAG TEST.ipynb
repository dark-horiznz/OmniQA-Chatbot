{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8a7dc2c-506a-45b0-b171-4b912bf8c477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -qqq langchain langchain_groq langchain_pinecone pinecone-client pypdf langchain groq google-generativeai duckduckgo-search lxml huggingface_hub datasets beautifulsoup4 requests selenium python-dotenv aiohttp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36459e81-3d6d-40aa-87de-12cc2d289191",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aditya/miniconda3/envs/aditya/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "import google.generativeai as genai\n",
    "from langchain.document_loaders import UnstructuredPDFLoader, PyPDFLoader\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pinecone import Pinecone\n",
    "from langchain.schema import Document\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from typing import List\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e78ac98-50bd-4441-bf9d-ff9c8e72f04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "data = load_dataset('lavita/ChatDoctor-HealthCareMagic-100k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd13f707-ced2-40e7-9c80-8e3a931ed71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data['train'].shuffle(42)[:5000])[['input' , 'output']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52272806-fc65-4781-ad2b-3b167f6c70b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'input':'question' , 'output':'answer'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f471d13-7681-4903-8ca5-15d6b8080117",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "os.environ['LANGCHAIN_API_KEY'] = '<YOUR API KEY>'\n",
    "os.environ['GROQ_API_KEY'] = '<YOUR API KEY>'\n",
    "os.environ['PINECONE_API_KEY'] = '<YOUR API KEY>'\n",
    "os.environ['PINECONE_ENV'] = 'gemini-rag'\n",
    "os.environ[\"GEMINI_API_KEY\"] = '<YOUR API KEY>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f43aa65-f4c8-4f45-9cb2-4e3fb4b727f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeminiEmbeddings(Embeddings):\n",
    "    def __init__(self, api_key):\n",
    "        genai.configure(api_key=api_key)\n",
    "        self.model_name = \"models/embedding-001\"  \n",
    "\n",
    "    def embed_documents(self, texts):\n",
    "        return [self._convert_to_float32(genai.embed_content(model=self.model_name, content=text, task_type=\"retrieval_document\")[\"embedding\"]) for text in texts]\n",
    "\n",
    "    def embed_query(self, text):\n",
    "        response = genai.embed_content(model=self.model_name, content=text, task_type=\"retrieval_query\")\n",
    "        return self._convert_to_float32(response[\"embedding\"])\n",
    "\n",
    "    @staticmethod\n",
    "    def _convert_to_float32(embedding):\n",
    "        return np.array(embedding, dtype=np.float32).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "443a6a3a-9efd-4a62-bfd9-a988a24bdb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "embeddings = GeminiEmbeddings(api_key=os.environ[\"GEMINI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e547514c-6d9e-4739-997d-b79bca82f67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(os.environ['PINECONE_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5728ca10-054d-428e-83c7-f1023b9d17cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [ \n",
    "    Document(page_content=f\"Q: {row['question']}\\nA: {row['answer']}\", metadata={'Page index':i+1})\n",
    "    for i, row in df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "833ad0e1-65a5-479c-b305-746fbfd39b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "def upsert(docs , embeddings , split_size = 100):\n",
    "    for start in tqdm(range(0, len(docs), split_size)):\n",
    "        doc = docs[start : start + split_size]\n",
    "        vectorstore = PineconeVectorStore.from_documents(\n",
    "            doc,\n",
    "            embeddings,\n",
    "            index_name= os.environ['PINECONE_ENV']\n",
    "        )\n",
    "        time.sleep(30)\n",
    "    return vectorstore\n",
    "    \n",
    "def load_existing(embeddings):\n",
    "    vectorstore = PineconeVectorStore.from_existing_index(\n",
    "    embedding=embeddings,                   \n",
    "    index_name=os.environ[\"PINECONE_ENV\"],   \n",
    ")\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cae96bc-ec2f-4122-86ea-1e6506c5004e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 50/50 [1:12:25<00:00, 86.92s/it]\n"
     ]
    }
   ],
   "source": [
    "vectorstore = upsert(docs , embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14130541-9c0f-425b-813b-b75719c115b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMChain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "answer_template = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "You are a helpful assistant.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "User question:\n",
    "{question}\n",
    "\n",
    "Task: Provide a concise, accurate answer based solely on the context.\n",
    "If the context does NOT contain the information needed to answer the question, reply exactly:\n",
    "\"No suitable answer found in database.\"\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "clarify_template = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "You answered:\n",
    "{answer}\n",
    "\n",
    "The user originally asked:\n",
    "{question}\n",
    "\n",
    "Task: Determine if more information is needed to answer correctly.\n",
    "- If you CANNOT answer because the database lacked relevant information, reply exactly `ENOUGH`.\n",
    "- If you NEED more info, ask a single, specific follow-up question.\n",
    "- If you have enough context to be confident, reply exactly `ENOUGH`.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "summary_template = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "Here are the question/answer pairs that occurred:\n",
    "{history}\n",
    "\n",
    "Task: Provide a concise final summary of the information above.\n",
    "If all answers were 'No suitable answer found in database.', reply:\n",
    "\"No information available to summarize.\"\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "web_summary_template = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "Here is the webcontext we have scraped it from internet:\n",
    "{history}\n",
    "\n",
    "Task: Provide a concise final summary of the information above.\n",
    "If all answers are not relevent simply reply 'No relevent information found on the web'.\n",
    "If relevent content is found, summarise the content properly and properly cite it as web search content.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "final_summary_template = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "Here is the webcontext we have scraped it from internet:\n",
    "{web}\n",
    "Below is the context we have found from the corpus text:\n",
    "{text}\n",
    "\n",
    "Task: Provide a concise and detailed final summary of the information above.\n",
    "If all answers are not relevent simply reply 'No relevent information Is available please contact support'.\n",
    "If relevent content is found, summarise the content properly and properly cite content, give more priority to corpus text.\n",
    "If corpus text is less relevent then give priority to web content.\n",
    "Properly cite web content in the final summary. Make it sure the user knows the additional answer is from the web.\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74aeebe5-782e-4ec0-915b-1d0178a348a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nl/938w28k95hvcyj9_7qm693j80000gn/T/ipykernel_16994/2986635732.py:1: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  answer_chain = LLMChain(\n"
     ]
    }
   ],
   "source": [
    "answer_chain = LLMChain(\n",
    "    llm=ChatGroq(model=\"llama3-70b-8192\"), \n",
    "    prompt=answer_template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8c16a20-1cab-4b5c-8656-3b7ca0c5ee61",
   "metadata": {},
   "outputs": [],
   "source": [
    "clarify_chain = LLMChain(\n",
    "    llm=ChatGroq(model=\"llama3-70b-8192\", temperature=0.2),\n",
    "    prompt=clarify_template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "463cfacc-445e-4854-9459-f40c515b7670",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_chain = LLMChain(\n",
    "    llm=ChatGroq(model=\"llama3-70b-8192\"),\n",
    "    prompt=summary_template,\n",
    ")\n",
    "\n",
    "web_summary_chain = LLMChain(\n",
    "    llm=ChatGroq(model=\"llama3-70b-8192\"),\n",
    "    prompt=web_summary_template,\n",
    ")\n",
    "\n",
    "final_summary_chain = LLMChain(\n",
    "    llm=ChatGroq(model=\"llama3-70b-8192\"),\n",
    "    prompt=final_summary_template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91e55dd-4b8c-4b9d-98ca-8e9e35a7c90f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b06c00f-a986-4ca2-8c62-a8619c3bbc71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e36e1d-5f2f-481d-87e2-8522dda8883e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d89c52de-59b7-4741-8dec-1d9922d48d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_clarifying_qa(user_question: str,\n",
    "                       vectorstore: PineconeVectorStore,\n",
    "                       max_queries: int = 3,\n",
    "                       k_retrieval: int = 3):\n",
    "    history = []\n",
    "    q = user_question\n",
    "\n",
    "    for depth in range(max_queries):\n",
    "        docs = vectorstore.similarity_search(q, k=k_retrieval)\n",
    "        ctx  = \"\\n\\n\".join(d.page_content for d in docs)\n",
    "\n",
    "        a = answer_chain.run(question=q, context=ctx)\n",
    "        history.append((q, a))\n",
    "\n",
    "        if a.strip().lower() == \"no suitable answer found in database.\":\n",
    "            break\n",
    "\n",
    "        follow = clarify_chain.run(question=q, answer=a).strip()\n",
    "        if follow.upper() == \"ENOUGH\":\n",
    "            break\n",
    "\n",
    "        q = follow\n",
    "\n",
    "    hist_text = \"\\n\".join(f\"Q: {x}\\nA: {y}\" for x, y in history)\n",
    "    summary = summary_chain.run(history=hist_text)\n",
    "\n",
    "    return {\"history\": history, \"summary\": summary}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc981744-c73b-4508-8a46-ca5b263b1b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nl/938w28k95hvcyj9_7qm693j80000gn/T/ipykernel_16994/858806572.py:12: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  a = answer_chain.run(question=q, context=ctx)\n"
     ]
    }
   ],
   "source": [
    "q = 'I am having high fever and nausea since this morning.'\n",
    "result = self_clarifying_qa(q, vectorstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc92b958-f48e-430b-a608-4fbdb9faeb6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here is a concise final summary of the information:\\n\\nA person experiencing high fever and nausea since morning may have a viral illness or stomach infection. They should take paracetamol for fever relief, consider antibiotics if they persist, and stay hydrated with water and a light diet. If symptoms worsen or they experience severe abdominal pain or vomiting, they should seek further guidance from a doctor.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['summary']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e851ec3e-96b8-46f3-9590-22bc89606400",
   "metadata": {},
   "source": [
    "# Web Scraping part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7b5a484-312e-4a7f-8f14-1e5fcd878ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from lxml import html\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ef4460-8db0-42d1-b1eb-2ae7702c90f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \"def get_gemini_model(model_name = \\\"gemini-2.0-flash-lite\\\", temperature = 0.4):\\n\",\n",
    "    return genai.GenerativeModel(model_name)\n",
    "\n",
    "def get_generation_config(temperature = 0.4):\n",
    "    return {\n",
    "        \"temperature\": temperature,\n",
    "        \"top_p\": 1,\n",
    "        \"top_k\": 1,\n",
    "        \"max_output_tokens\": 2048,\n",
    "    }\n",
    "\n",
    "def get_safety_settings():\n",
    "    return [\n",
    "        {\"category\": category, \"threshold\": \"BLOCK_NONE\"}\n",
    "        for category in [\n",
    "            \"HARM_CATEGORY_HARASSMENT\",\n",
    "            \"HARM_CATEGORY_HATE_SPEECH\",\n",
    "            \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "            \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "        ]\n",
    "    ]\n",
    "    \n",
    "def generate_gemini_response(model, prompt):\n",
    "    response = model.generate_content(\n",
    "        prompt,\n",
    "        generation_config=get_generation_config(),\n",
    "        safety_settings=get_safety_settings()\n",
    "    )\n",
    "    if response.candidates and len(response.candidates) > 0:\n",
    "        return response.candidates[0].content.parts[0].text\n",
    "    return ''\n",
    "\n",
    "def create_search_prompt(query, context = \"\"):\n",
    "    system_prompt = \"\"\"You are a smart assistant designed to determine whether a query needs data from a web search or can be answered using a document database. \n",
    "    Consider the provided context if available. \n",
    "    If the query requires external information, No context is provided, Irrelevent context is present or latest information is required, then output the special token <SEARCH> \n",
    "    followed by relevant keywords extracted from the query to optimize for search engine results. \n",
    "    Ensure the keywords are concise and relevant. If document data is sufficient, simply return blank.\"\"\"\n",
    "    \n",
    "    if context:\n",
    "        return f\"{system_prompt}\\n\\nContext: {context}\\n\\nQuery: {query}\"\n",
    "    \n",
    "    return f\"{system_prompt}\\n\\nQuery: {query}\"\n",
    "\n",
    "def create_summary_prompt(content):\n",
    "    return f\"\"\"Please provide a comprehensive yet concise summary of the following content, highlighting the most important points and maintaining factual accuracy. Organize the information in a clear and coherent manner:\n",
    "\n",
    "Content to summarize:\n",
    "{content}\n",
    "\n",
    "Summary:\"\"\"\n",
    "\n",
    "def init_selenium_driver():\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    \n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    return driver\n",
    "\n",
    "def extract_static_page(url):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=5)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.text, 'lxml')\n",
    "        \n",
    "        text = soup.get_text(separator=\" \", strip=True)\n",
    "        return text[:5000]\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching page: {e}\")\n",
    "        return None\n",
    "        \n",
    "def extract_dynamic_page(url, driver):\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(random.uniform(2, 5))\n",
    "        \n",
    "        body = driver.find_element(By.TAG_NAME, \"body\")\n",
    "        ActionChains(driver).move_to_element(body).perform()\n",
    "        time.sleep(random.uniform(2, 5))\n",
    "        \n",
    "        page_source = driver.page_source\n",
    "        tree = html.fromstring(page_source)\n",
    "        \n",
    "        text = tree.xpath('//body//text()')\n",
    "        text_content = ' '.join(text).strip()\n",
    "        return text_content[:1000]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching dynamic page: {e}\")\n",
    "        return None\n",
    "\n",
    "def scrape_page(url):\n",
    "    if \"javascript\" in url or \"dynamic\" in url:\n",
    "        driver = init_selenium_driver()\n",
    "        text = extract_dynamic_page(url, driver)\n",
    "        driver.quit()\n",
    "    else:\n",
    "        text = extract_static_page(url)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def scrape_web(urls, max_urls = 5):\n",
    "    texts = []\n",
    "    \n",
    "    for url in tqdm(urls[:max_urls], desc=\"Scraping websites\"):\n",
    "        text = scrape_page(url)\n",
    "        \n",
    "        if text:\n",
    "            texts.append(text)\n",
    "        else:\n",
    "            print(f\"Failed to retrieve content from {url}\")\n",
    "            \n",
    "    return texts\n",
    "\n",
    "def check_search_needed(model, query , context):\n",
    "    prompt = create_search_prompt(query , context)\n",
    "    response = generate_gemini_response(model, prompt)\n",
    "    \n",
    "    if \"<SEARCH>\" in response:\n",
    "        search_terms = response.split(\"<SEARCH>\")[1].strip()\n",
    "        return True, search_terms\n",
    "    return False, None\n",
    "\n",
    "def summarize_content(model, content):\n",
    "    prompt = create_summary_prompt(content)\n",
    "    return generate_gemini_response(model, prompt)\n",
    "\n",
    "def process_query(query , context = ''):\n",
    "    model = get_gemini_model()\n",
    "    search_tool = DuckDuckGoSearchRun()\n",
    "    \n",
    "    needs_search, search_terms = check_search_needed(model, query , context)\n",
    "    \n",
    "    result = {\n",
    "        \"original_query\": query,\n",
    "        \"needs_search\": needs_search,\n",
    "        \"search_terms\": search_terms,\n",
    "        \"web_content\": None,\n",
    "        \"summary\": None,\n",
    "        \"raw_response\": None\n",
    "    }\n",
    "    \n",
    "    if needs_search:\n",
    "        search_results = search_tool.run(search_terms)\n",
    "        result[\"web_content\"] = search_results\n",
    "        \n",
    "        summary = summarize_content(model, search_results)\n",
    "        result[\"summary\"] = summary\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e8636cf-e054-480d-a075-f8d1c1325f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(question , context = '' , debug = False):\n",
    "    result = process_query(question , context = '')\n",
    "    if debug:\n",
    "        print(\"\\nQuery Results:\")\n",
    "        print(f\"Search needed: {result['needs_search']}\")\n",
    "        \n",
    "        if result['needs_search']:\n",
    "            print(f\"\\nSearch terms used: {result['search_terms']}\")\n",
    "            print(\"\\nSummary of findings:\")\n",
    "            print(result['summary'])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "251ec45b-275d-4bad-88f2-ad47e17661b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'original_query': 'I am having high fever and nausea since this morning.',\n",
       " 'needs_search': True,\n",
       " 'search_terms': 'high fever nausea treatment',\n",
       " 'web_content': \"Call your healthcare professional if the fever doesn't respond to the medicine, stays at 103 F (39.4 C) or higher or lasts longer than three days. There is a problem with information submitted for this request. Evans SS, Repasky EA, Fisher DT. Fever and the thermal regulation of immunity: the immune system feels the heat. Nat Rev Immunol. 2015;15(6):335-49. doi:10.1038/nri3843 Baran G, Turan E. Investigation of the effect of the training on fever and febrile convulsion management given to pediatric nurses on their knowledge level. Int J Caring Sci. 2018;11(1):478-87. The appropriate course of treatment is needed to eliminate the symptoms of fever. The most common treatment options for acute febrile illness include antibiotics, multivitamins, antiviral medications, or antimalarial drugs. These medicines help avoid lethargy, dizziness, nausea, headaches, and vomiting. ... weakness, muscle pain, or high fever. ... For example, a fever accompanied by vomiting and diarrhea may signal gastroenteritis, and a fever associated with coughing, shortness of breath and grayish-yellow phlegm may indicate pneumonia. Diagnosis. In pinpointing a fever's cause, your doctor may ask about: Cold or flu symptoms; Abdominal pain, nausea, vomiting or diarrhea This can occur if the fever causes you to sweat excessively, or is associated with vomiting or diarrhea. Signs of dehydration include thirst, dry skin, dry mouth, chills, feeling tired or weak, and dark-colored urine. Other fever remedies for adults. When to Call Your Doctor. Fevers above 103°F ; Persistent fever.\",\n",
       " 'summary': 'Seek medical attention if your fever is unresponsive to medication, reaches or exceeds 103°F (39.4°C), or persists beyond three days.  While treating fever, address associated symptoms like lethargy, dizziness, nausea, headaches, vomiting, muscle pain, and weakness.  Treatment depends on the underlying cause and may include antibiotics, antivirals, antimalarials, or supportive care like multivitamins.  For example, accompanying symptoms like vomiting and diarrhea may suggest gastroenteritis, while coughing and shortness of breath with grayish-yellow phlegm could indicate pneumonia.  A doctor diagnoses the cause by considering symptoms like cold/flu, abdominal issues, or others.  Dehydration, indicated by thirst, dry mouth/skin, chills, fatigue, and dark urine, can be a complication of fever due to fluid loss.\\n',\n",
       " 'raw_response': None}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run('I am having high fever and nausea since this morning.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dd50f506-3983-4bf2-a799-0d053a6103a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def QA_chain_with_websearch(user_question, vectorstore, max_queries = 3, k_retrieval = 3 , web_mode = True):\n",
    "    result = self_clarifying_qa(user_question , vectorstore , max_queries , k_retrieval)\n",
    "    if web_mode:\n",
    "        scrape_summary = run(user_question)\n",
    "        print('Searching The web!')\n",
    "        if scrape_summary:\n",
    "            web_content = scrape_summary['web_content']\n",
    "            web_summary = web_summary_chain.run(history=web_content)\n",
    "            if result['summary'].strip().lower() == \"no suitable answer found in database.\":\n",
    "                return web_summary\n",
    "    try:\n",
    "        final = final_summary_chain.run(web = web_summary , text = result['summary'])\n",
    "        return final\n",
    "    except:\n",
    "        return result['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd425a97-33a7-4676-9911-2bfa3f7c6989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching The web!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Here is a concise and detailed final summary of the information:\\n\\n**Fever and Nausea Management**\\n\\nBased on the corpus text, if you are experiencing high fever and nausea, it is recommended to:\\n\\n* Take paracetamol for fever relief\\n* Stay hydrated\\n* Avoid outside or junk food\\n\\nIf your symptoms worsen or other severe symptoms appear, consider visiting the nearest Emergency Room.\\n\\n**Additional Guidelines from Web Content**\\n\\n* For adults, seek medical attention if fever is over 104°F (40°C) or 105°F (40.5°C) for emergency care. (Source: Web search content)\\n* For newborns (0-3 months), call healthcare provider or go to emergency room if fever is 100.4°F (38°C). (Source: Web search content)\\n* Viral gastroenteritis (stomach flu) can cause fever, diarrhea, nausea, and vomiting, and is often spread through contact with an infected person or contaminated food/water. (Source: Web search content)\\n\\nNote: The additional guidelines from web content are provided for reference and may not be directly related to the user's symptoms. If you have any concerns, please contact a healthcare provider or visit an Emergency Room for further assistance.\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = 'I am having high fever and nausea since this morning.'\n",
    "QA_chain_with_websearch(question , vectorstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23765c83-048d-4279-9dc7-a2e74f7bb647",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aditya",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
